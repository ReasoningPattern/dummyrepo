
Okay, let's see. I need to generate the Python code for the find_tags function based on the given signature and docstring. The function is supposed to find tags in text, ignoring those inside code blocks. Also, if a replacer function is provided, it should replace the tag words with the result of that function. The return is a set of tags and the modified text.

First, I need to think about how to identify tags. The docstring mentions ignoring tags inside code blocks. So maybe code blocks are marked with something like triple backticks or specific syntax. But the problem is, how to detect those and skip processing tags within them.

Wait, the user mentioned that the function is part of a larger codebase with certain imports and other functions. The imported packages are typing, urllib, re, bleach. So maybe using regular expressions with the re module. Also, there's a variable ILLEGAL_TAG_CHARS, which might be used to check if a tag is valid.

The function decode_if_bytes and encode_if_text might be handling text encoding/decoding. But maybe that's not directly relevant here. The main task is to find tags, replace them if needed, and return the set and modified text.

So the approach could be:

1. Split the text into parts, identifying code blocks and non-code blocks.
2. In non-code blocks, find tags, possibly using regex.
3. For each found tag, check if it's valid (using test_tag? Or ILLEGAL_TAG_CHARS?).
4. If a replacer is provided, replace the tag with replacer(tag).
5. Collect all unique tags into a set.
6. Return the set and the modified text.

But how to split the text into code blocks? Maybe code blocks are enclosed in triple backticks. So using a regex to split the text into code and non-code sections. For example, using re.split with a pattern that captures code blocks, then processing the non-code parts.

Alternatively, process the text while keeping track of whether we're inside a code block. For example, using a state machine: when we encounter a code block start (like ```), toggle the state, and skip processing tags until the end of the code block.

But how to detect code blocks? Maybe the code blocks are marked by triple backticks, and the regex can find those. So perhaps using a regex to find all occurrences of code blocks and then process the rest of the text.

Another thing: the function returns a set of tags and the modified text. So the tags are the words that were found and possibly replaced.

Let me think about the steps:

- Use regex to find all words that are tags. But what defines a tag? The docstring mentions test_tag, which might be a function that checks if a word is a valid tag. But since that's not provided here, maybe the tags are words that match a certain pattern, like starting with a letter, followed by letters or numbers, etc. Alternatively, maybe the tags are determined by the presence of certain characters, using ILLEGAL_TAG_CHARS.

Wait, the context mentions ILLEGAL_TAG_CHARS. So maybe a tag is a word that doesn't contain any of those illegal characters. So first, split the text into words, check each word against ILLEGAL_TAG_CHARS, and if it's valid, consider it a tag.

But how to split the text into words? Maybe using regex to find all words, but considering that tags are probably in certain contexts. However, without more info, perhaps the code uses a regex pattern to find potential tags.

Alternatively, maybe the tags are words that are surrounded by non-word characters, or something like that.

But given that the user hasn't provided the exact implementation of test_tag or ILLEGAL_TAG_CHARS, I need to make assumptions based on the function's purpose.

Assuming that test_tag is a function that returns True if a word is a valid tag, then the code would iterate through the text, find words, check if they are valid tags, and collect them.

But the problem is handling code blocks. So, the code needs to process the text, skipping any parts that are inside code blocks.

So, perhaps the approach is:

- Split the text into segments, some of which are code blocks (to be ignored) and others that are regular text (to be processed for tags).

How to split the text into code blocks and other text? For example, code blocks are enclosed in triple backticks. So using a regex to split the text into code blocks and other parts. For example, using re.split with a pattern that captures the code blocks and the other text.

But splitting might not be straightforward. Alternatively, using a regex to find all code blocks and then process the remaining text.

Alternatively, iterate through the text, keeping track of whether we're inside a code block. When not inside a code block, process the text for tags.

But how to detect the start and end of code blocks. Let's assume code blocks start with ``` and end with ```.

So, the code could be:

Initialize a list to hold the processed text parts and a set for tags.

Initialize a variable in_code_block as False.

Iterate through the text, splitting it into parts when code blocks are encountered. For example, using re.finditer to find all code blocks and the text between them.

But perhaps using a regex to split the text into code blocks and non-code parts. For example, using re.split with a pattern that matches code blocks, and then processing the non-code parts.

But splitting may not capture the code blocks properly. Maybe using re.findall to get all the code blocks and the other text.

Alternatively, using a regex that matches either code blocks or other text. For example, using re.findall with a pattern like (```.*?```)|([^```]+), but that's a rough idea.

Once the text is split into code and non-code parts, process the non-code parts for tags.

In the non-code parts, find all words that are valid tags (using test_tag or checking against ILLEGAL_TAG_CHARS), collect them into the set, and replace them if a replacer is provided.

But how to find the words? Maybe using a regex to find all words, then checking each for validity.

So, for each non-code part:

- Use re.findall(r'\b\w+\b', text_part) to get all words.

But maybe that's too simplistic. Alternatively, using a more precise regex based on what constitutes a tag.

But without knowing the exact definition, perhaps the code uses the test_tag function. However, since that's not provided, maybe the code uses the ILLEGAL_TAG_CHARS to check if a word is a valid tag. For example, if a word doesn't contain any of the illegal characters, it's considered a tag.

Assuming that ILLEGAL_TAG_CHARS is a string containing characters that are not allowed in tags. So, for a word to be a tag, it must not contain any of those characters.

So, the code would check for each word if all characters are allowed (i.e., not in ILLEGAL_TAG_CHARS).

Once the valid tags are identified, they are added to the set. Then, if a replacer is provided, the word is replaced with replacer(word).

But how to replace the words in the text. For example, if the original text is "hello world", and "hello" is a tag, then after replacement, it becomes replacer("hello") + " world".

But replacing the words in the text requires that we find all occurrences of the tags and replace them. However, the function's docstring says that it replaces the tag word with the result of the replacer function. So, it's possible that the function is supposed to replace each occurrence of the tag in the text, not just the first occurrence.

But how to do that. For example, using re.sub with a function that replaces each match.

But first, collect all the tags, then for each tag in the text, replace it with replacer(tag).

But the order might matter. For example, if a tag is a substring of another tag. However, assuming that the tags are unique and non-overlapping.

Alternatively, process the text in a way that replaces all instances of the tags.

But this could be complex. Let's think of the steps again:

1. Split the text into code and non-code parts.

2. For each non-code part:

   a. Find all words that are valid tags (using test_tag or ILLEGAL_TAG_CHARS).

   b. Collect these tags into a set.

   c. Replace each occurrence of these tags in the text with the result of replacer(tag) if replacer is provided.

But how to do that. For example, using a regex that matches any of the tags, and then replacing them.

But since the tags are found in the text, perhaps the code first collects all the tags, then for each tag, replaces it in the text.

But this could be done with a regex substitution that uses a lambda function to replace each match.

But the problem is that the same word may be a tag multiple times, and the replacer may return different values each time. However, the replacer is a function that takes the tag word and returns the replacement.

So, for example, if the tag is 'hello', and the replacer is lambda x: x.upper(), then 'hello' becomes 'HELLO'.

But to do this, the code could first collect all the tags, then for each tag in the text, replace it with the result of the replacer.

But how to do this efficiently. One approach is to use re.sub with a function that checks if the matched word is a tag and then applies the replacer.

But since the tags are collected first, perhaps the code can build a regex pattern that matches any of the tags, then perform substitution.

But that would require building a regex pattern with all the tags, which could be done with re.compile(r'\b(' + '|'.join(map(re.escape, tags)) + r')\b'), and then using re.sub with a lambda that replaces each match.

But this approach would require that the tags are known before processing the text. However, the tags are found by scanning the text, which may include the same tags again. So this seems a bit circular.

Alternatively, process the text in a way that for each word, check if it's a valid tag, and if so, replace it. But this would require scanning the text again after collecting the tags.

But that's not efficient, but perhaps acceptable for the purpose of this function.

Alternatively, during the initial scan for tags, also perform the replacement. But that would require modifying the text as we go.

Hmm. Let's think of an approach that first collects all the tags, then replaces them in the text.

So:

- Split the text into code and non-code parts.

- For each non-code part, find all valid tags (using test_tag or ILLEGAL_TAG_CHARS), add them to a set.

- Once all tags are collected, build a regex pattern that matches any of the tags, and replace them in the text.

But how to split the text into code and non-code parts.

Assuming code blocks are enclosed in triple backticks. So, the code can use a regex to split the text into code blocks and other text.

For example:

import re

code_block_pattern = re.compile(r'```.*?```', re.DOTALL)

Then, split the text into parts that are code blocks and parts that are not. But how to do that.

Alternatively, using re.split to split the text into code blocks and other parts. But that might not work directly. Another approach is to use re.finditer to find all code blocks and the text between them.

For example:

text_parts = []
current_pos = 0

for match in code_block_pattern.finditer(text):
    start, end = match.span()
    if current_pos < start:
        text_parts.append(('non_code', text[current_pos:start]))
    text_parts.append(('code', text[start:end]))
    current_pos = end

if current_pos < len(text):
    text_parts.append(('non_code', text[current_pos:]))

Then, for each part in text_parts, if it's non_code, process it for tags.

Once all non_code parts are processed for tags, collect the tags into a set.

Then, build a regex pattern that matches any of the tags, and replace them in the original text (but only in the non-code parts? Or in the entire text? The docstring says that the replacer is applied to the tag word, which may be in the text. But the code blocks are to be ignored, so the replacement should not happen inside code blocks.

Wait, the function's docstring says: "Tries to ignore tags inside code blocks." So, the tags inside code blocks are not considered, and the replacement is done only outside code blocks.

So, the approach is:

- Process the non-code parts for tags, collect them, and replace them in the non-code parts.

But how to do that. For example, after collecting the tags, we need to replace them in the non-code parts of the text.

But the original text may have code blocks and non-code parts. So, the replacement should be done only in the non-code parts.

So, perhaps during the initial splitting into code and non-code parts, we can process each non-code part for tags and replacement.

So, here's a possible plan:

Initialize a list to hold the processed parts.

For each part in text_parts:

   if it's a code part, add it to the processed parts as-is.

   else:

      process this non-code part to find tags and replace them.

So, during processing the non-code part:

   find all valid tags in this part.

   add them to the set.

   replace the tags in this part with the replacer's result.

But how to find and replace the tags in this part. For example, using a regex substitution with the replacer function.

But the replacer is a function that takes the tag word and returns the replacement. So, for each tag found in the non-code part, replace it with replacer(tag).

But how to do that. For example, using re.sub with a lambda function that checks if the matched word is a tag and applies the replacer.

But this requires knowing which words are tags. So, perhaps during processing the non-code part, first collect all the tags, then build a regex pattern that matches those tags, and perform substitution.

Alternatively, during the initial scan for tags, also perform the replacement.

But this could be done as follows:

For a non-code part:

   find all words in the part.

   for each word, check if it's a valid tag.

   collect the valid tags into the set.

   then, for each valid tag, replace all occurrences in the part with replacer(tag) if replacer is provided.

But how to do that. For example, using re.sub with a function that checks if the word is a tag.

But this requires that during the replacement, we check if the matched word is a tag. However, since we have already collected the tags, perhaps we can build a regex that matches any of the tags and perform substitution.

But this would require that during the replacement phase, we have the list of tags.

So, here's a possible approach:

For each non-code part:

   collect all valid tags in this part.

   add them to the overall set.

   build a regex pattern that matches any of the tags in this part.

   replace each occurrence of these tags with replacer(tag) if replacer is provided.

But this would require that for each non-code part, we first find the tags, then build a regex for them, and replace them.

But this could be done with:

tags_in_part = [ ... ]

pattern = re.compile(r'\b(' + '|'.join(re.escape(tag) for tag in tags_in_part) + r')\b')

replaced_part = pattern.sub(lambda m: replacer(m.group(0)), part)

But this would replace all occurrences of the tags in the part.

But this approach may not capture all tags, especially if the same tag appears multiple times. Also, the order of tags in the regex may affect the matching, but using word boundaries should help.

But how to collect the tags_in_part. For example, using re.findall(r'\b\w+\b', part) to get all words, then filter them based on the test_tag or ILLEGAL_TAG_CHARS.

Assuming that the test_tag function is available, but since it's not provided, perhaps the code uses the ILLEGAL_TAG_CHARS.

So, for each word in the non-code part:

   if all(c not in ILLEGAL_TAG_CHARS for c in word):

       add to tags_in_part.

Once that's done, proceed to replace them.

But this may not be the exact logic, but given the context, this is a possible approach.

Putting it all together:

The code would:

- Split the text into code and non-code parts.

- For each non-code part:

   - Find all words that are valid tags (based on ILLEGAL_TAG_CHARS).

   - Add them to the set.

   - Replace them in the part using the replacer function.

- Combine the processed parts (code parts as-is, non-code parts with replacements) to form the modified text.

Now, implementing this in Python.

But the code needs to use the imported modules: typing, urllib, re, bleach. Also, the variables like ILLEGAL_TAG_CHARS are available.

So, the code for find_tags:

import re
from typing import Tuple, Set

def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:
    # Split text into code and non-code parts
    code_block_pattern = re.compile(r'```.*?```', re.DOTALL)
    text_parts = []
    current_pos = 0
    for match in code_block_pattern.finditer(text):
        start, end = match.span()
        if current_pos < start:
            text_parts.append(('non_code', text[current_pos:start]))
        text_parts.append(('code', text[start:end]))
        current_pos = end
    if current_pos < len(text):
        text_parts.append(('non_code', text[current_pos:]))

    tags = set()
    modified_parts = []

    for part_type, part in text_parts:
        if part_type == 'code':
            modified_parts.append(part)
        else:
            # Find valid tags in this part
            words = re.findall(r'\b\w+\b', part)
            valid_tags = []
            for word in words:
                if all(c not in ILLEGAL_TAG_CHARS for c in word):
                    valid_tags.append(word)
            # Add to tags set
            tags.update(valid_tags)
            # Replace tags in this part if replacer is provided
            if replacer:
                # Build regex pattern for valid tags
                pattern = re.compile(r'\b(' + '|'.join(re.escape(tag) for tag in valid_tags) + r')\b')
                replaced_part = pattern.sub(replacer, part)
                modified_parts.append(replaced_part)
            else:
                modified_parts.append(part)

    # Combine modified parts
    modified_text = ''.join(modified_parts)
    return tags, modified_text

Wait, but the code above uses re.escape on each tag, which is correct. However, the pattern is built as r'\b(...)\b', which matches whole words. But the replacement is done with pattern.sub(replacer, part). However, the replacer is a function that takes the matched group. So, in the lambda, m.group(0) would be the matched tag. So, the code should use a lambda that calls replacer with m.group(0).

But in the code above, the line is:

replaced_part = pattern.sub(replacer, part)

But that would pass the replacer function as the replacement function. However, the replacer is supposed to take the tag word and return the replacement. So, the code should use a lambda that applies the replacer to the matched group.

Wait, the pattern.sub method's second argument can be a function. So, if replacer is a function, then pattern.sub(replacer, part) would call replacer with the matched group. But the replacer is supposed to take the tag word as an argument. So, this should be correct.

But in the code above, the line is:

replaced_part = pattern.sub(replacer, part)

But if replacer is a function, then that's correct. However, if the replacer is not a function, but the default is None, then we need to check if replacer is not None before doing this.

Wait, in the code, the replacer is passed as a parameter, with a default of None. So, in the code, inside the else clause (when part_type is non_code), we check if replacer is provided. Then, build the pattern and do the substitution.

But the code uses pattern.sub(replacer, part). However, the replacer is a function that takes the tag word and returns the replacement. So, the code is correct here.

But what if the same tag appears multiple times in the part? The pattern.sub would replace all occurrences.

But this approach may have issues with overlapping tags or tags that are substrings of each other. For example, if a tag is 'tag' and another is 'tags', the regex may match 'tag' in 'tags', but the code would replace 'tag' with replacer('tag'), leaving 's' as part of the word. However, the regex uses word boundaries, so it should match whole words only.

But the regex \b(...)\b ensures that the entire word is matched. So, for example, in the word 'tag', it would match, but in 'tags', it would not, unless 'tags' is also a valid tag.

So, this approach should work.

Another thing to consider: the code uses re.findall(r'\b\w+\b', part) to get words. However, this may not capture all possible tag words, depending on the definition. But given the context, this is a reasonable approach.

Also, the code uses ILLEGAL_TAG_CHARS, which is presumably a string of characters that are not allowed in tags. So, for a word to be a valid tag, none of its characters can be in ILLEGAL_TAG_CHARS.

Now, putting all this into the code.

But the code needs to be in Python, using the given imports and variables.

Another thing: the original text may have bytes, so maybe decode_if_bytes is used. However, the function's parameters are text: str, so it's assumed to be a string. So, perhaps no need for decoding here.

Also, the function returns a set of tags and the modified text. The code above does that.

But what about the case where the same tag appears in multiple non-code parts? The set will automatically handle duplicates.

So, this code should fulfill the requirements.

But I need to make sure that the code uses the correct variables and functions. For example, ILLEGAL_TAG_CHARS is a variable defined elsewhere.

Now, writing the code with these steps.
